## ğŸ©º Kalp HastalÄ±ÄŸÄ± Tahmini â€“ Makine Ã–ÄŸrenmesi Projesi

## Proje AmacÄ±
Projemiz, bireylerin saÄŸlÄ±k verilerinden (yaÅŸ, boy, kilo, tansiyon, kolesterol, glikoz vb.) yararlanÄ±larak **kalp hastalÄ±ÄŸÄ± riskini** tahmin etmeyi amaÃ§lamaktadÄ±r.

Bu projede amacÄ±mÄ±z farklÄ± makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ± kullandÄ±ktan sonra, karÅŸÄ±laÅŸtÄ±rarak **en doÄŸru ve en gÃ¼venilir tahmin modelini oluÅŸturmaktÄ±r.**



## ğŸ“ KullanÄ±lan Veri Seti
- **Kaynak:** [Kaggle â€“ Cardiovascular Disease Dataset](https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset)
- **Veri MiktarÄ±:** 70.000 gÃ¶zlem, 13 Ã¶zellik

Veri seti, yaÅŸ (gÃ¼n cinsinden), boy, kilo, kan basÄ±ncÄ±, kolesterol, glikoz, sigara, alkol, fiziksel aktivite gibi saÄŸlÄ±k parametrelerini iÃ§ermektedir.



## KullanÄ±lan YÃ¶ntemler ve Modeller

### ğŸ“Œ AÅŸamalar:
1. **Veri Ã–n Ä°ÅŸleme:** `id` kaldÄ±rÄ±ldÄ±, `age` gÃ¼n â†’ yÄ±l dÃ¶nÃ¼ÅŸÃ¼mÃ¼ yapÄ±ldÄ±, StandardScaler ile Ã¶lÃ§ekleme yapÄ±ldÄ± veriler Ã¶lÃ§eklendirildi.
2. **x ve y ayrÄ±mÄ±** yapÄ±ldÄ±.
3. **train_test_split:** %70 eÄŸitim / %30 test bÃ¶lmesi olacak ÅŸekilde ayarlandÄ±.
4. **Model Kurulumu:** AÅŸaÄŸÄ±daki algoritmalar ayrÄ± ayrÄ± test edildi:
    - LogisticRegression (baseline)
    - RandomForestClassifier
    - XGBoostClassifier
5. **Parametre Optimizasyonu:** AÅŸaÄŸÄ±daki optimizasyon yÃ¶ntemleri denendi ve en uygun olanÄ± seÃ§ildi.
    - GridSearchCV (Logistic Regression)
    - RandomizedSearchCV (Random Forest, XGBoost)
6. **Model Performans DeÄŸerlendirmesi:**
    - Accuracy
    - Precision
    - Recall
    - F1 Score
    - Confusion Matrix
                                                                                                              
  ÅŸeklindedir.



## âš™ï¸ En BaÅŸarÄ±lÄ± Modeller ve SonuÃ§larÄ±

| Model                           | Accuracy | Precision | Recall | F1 Score |
|---------------------------------|----------|-----------|--------|----------|
| Logistic Regression             | 0.72     | 0.74      | 0.68   | 0.71     |
| Random Forest (Optimize)        | 0.74     | 0.76      | 0.70   | 0.73     |
| XGBoost (Optimize)              | 0.74     | 0.76      | 0.70   | 0.73     |

**Verilen Karar:** XGBoost optimize edildiÄŸinde en yÃ¼ksek skoru verdi, ancak Logistic Regression daha sade, daha yorumlanabilir ve yeterince gÃ¼Ã§lÃ¼ olduÄŸu iÃ§in final model olarak tercih edildi.



## Denenen Ama Uygun GÃ¶rÃ¼lmeyen YÃ¶ntemler

- KNN: Veri bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ve yapÄ±sÄ± sebebiyle tercih edilmedi.
- SVM: EÄŸitim sÃ¼resi ve doÄŸrusal olmayan yapÄ± ihtimali nedeniyle dÄ±ÅŸlandÄ±.
- MLP (Yapay Sinir AÄŸÄ±): Gereksiz karmaÅŸÄ±klÄ±k yaratacaÄŸÄ± iÃ§in tercih edilmedi.



## Ã–ÄŸrenilenler

- Basit modeller, iyi hazÄ±rlanmÄ±ÅŸ veri ile Ã§ok gÃ¼Ã§lÃ¼ sonuÃ§lar verebilir.
- Her veri seti iÃ§in en iyi model farklÄ±dÄ±r: model deÄŸil **veri belirleyicidir**.
- F1 Score deÄŸerlendirmesi, dengesiz sÄ±nÄ±flarda en anlamlÄ± metriktir.
- `class_weight`, `GridSearch`, `RandomizedSearch` gibi tekniklerle model performansÄ± artÄ±rÄ±labilir.



## KullanÄ±lan KÃ¼tÃ¼phaneler
- pandas, numpy
- matplotlib, seaborn
- scikit-learn
- xgboost



## Projenin PaylaÅŸÄ±mÄ±

- **Kaggle:** 
- **GitHub:** 



## GeliÅŸtirme Ã–nerileri

- Yeni Ã¶zellikler (BMI, yaÅŸ grubu vs.) oluÅŸturulabilir.
- SMOTE ile sÄ±nÄ±f dengesi daha iyi hale getirilebilir.
- Ensemble modeller (Voting, Stacking) denenebilir.
- Cinsiyete gÃ¶re kalp hastalÄ±ÄŸÄ± etkisi araÅŸtÄ±rÄ±lÄ±p cinsiyet-hastalÄ±k iliÅŸkisi kurulabilir.
- Daha bÃ¼yÃ¼k veri setleriyle test edilebilir.
- Klinik Ã¶zellikler geniÅŸletilerek model zenginleÅŸtirilebilir.
- ArayÃ¼z mobil uyumlu hale getirilebilir.
